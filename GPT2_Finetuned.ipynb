{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU4TJXb3Ibr-",
        "outputId": "d70b5859-a69b-4749-dd1a-7a431ae76ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install datasets --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S1NY_jdUINQX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datasets import Dataset, DatasetDict, load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199,
          "referenced_widgets": [
            "079ebbc5439e4a01be35c19f83c0323a",
            "1df9667673a94b38bb1b3d7378eae1c8",
            "39c5a35c1973429180133ad23e8a5cde",
            "be54948112194cc09efefbbe2abdd6f5",
            "ff2a2d04d1ff4d308bd9d8f01fe7e279",
            "2af3a1d702f54e0a9832e7ca816eebaa",
            "02589d0ab582488ba3d0f5475737850f",
            "01d5c74954fb46ca93ef5c42ce023913",
            "0bb8d0bec0d046a382ee67ee20daaf0c",
            "9ac4effbf76245278743b1163a1319ff",
            "5832d418ac50402a911abd9efe7b41ac",
            "06a847efc99a4f1fbb48dbd3172ccc24",
            "ad4f8f294d3b407e9b3feca7bac94d43",
            "a5b8be414dfc4fb488c716f4e46f727b",
            "0792ad27b703412eb9cb2654e530f206",
            "5d7f2327ff7e48d08004afcbae096ed3",
            "7d32d3a63c0e4215aa8e7b8c181c029b",
            "721d993785684198a34dd91d64764c4d",
            "7e0bbd06fed949fa854b4785eee98a6d",
            "726ec8485e2041bbb62f106010baa39a",
            "ea23059a1732430db64d660ab52ed138",
            "13d594f7ea9b43d7a017d0d1e3fd14a6",
            "783c071afd6c43339a625317a74e278c",
            "3d68dbef5c464acea2fcac250fc37a9d",
            "012ed9b648c842c8aea0250c8af53e3b",
            "bec8e1c5b1484cfe9b42ebc64ea24b98",
            "085d5940dc12453f84bace41bb4aa158",
            "41c78fd8973b4bbc9c79d6e135f38f26",
            "634965bb3d074aa3a54a8920238be256",
            "114eb5be989447b3a0c8409c17f6a469",
            "f222d8e940a64cb6b376db42272bc268",
            "8d2df08448294a609b69c9174e4bc532",
            "6be3bdbcc1cd4245938a4e11a0b313b7",
            "dba61360ebdb4177be59627fe6e330f4",
            "8421331470284617859128639ce92a25",
            "52f01f5517874774be05bc06515f2ca8",
            "e481859cedc846529a81ba413912155a",
            "f2fd638e2b654a32bdb0754670ab739a",
            "687d3c1fb2af40bdbf452f5c18d5f4cf",
            "4c52bf9970514d35b25790ea41294c36",
            "4fb5f9e344914bfcb97565288e3b8aa5",
            "bf33f5aa65014c6c98a2710b82d7d181",
            "7b23f26733dc4de8986b4d64a2c77d4c",
            "780462fb987e4cafab7b113f5ede7879",
            "4a8079d080f8435bacf10960886bce47",
            "c1d58f83ac884c368b7387c594b1aed9",
            "50f17a9741df42cc89466b6d187c7463",
            "ae019d943fdf4b468409d3806a276117",
            "85365a90daaf4a068a780ee327071586",
            "aaf423b5d9fa48e59bac72ae3b1d2053",
            "08fe740553f249b698b2eacd3eac1245",
            "d758df3421364210b59ba9f9c543c3c0",
            "38f99a6a23644458bf13189cf39ea8f9",
            "4edf1d12ece04b33b08f7d443aede5c2",
            "c0eb591f9e1742299b99fdf90c9dc634"
          ]
        },
        "id": "1LchikQXIGmH",
        "outputId": "2746bf30-e89b-4c97-9d38-73a83add4e50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset parquet (C:/Users/pranu/.cache/huggingface/datasets/Whispering-GPT___parquet/Whispering-GPT--lex-fridman-podcast-f9b59d9d94797791/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        }
      ],
      "source": [
        "data = load_dataset(\"Whispering-GPT/lex-fridman-podcast\", split='train')\n",
        "data\n",
        "\n",
        "\n",
        "\n",
        "# Extract the features and their values\n",
        "features = data.features.keys()\n",
        "values = {feature: data[feature] for feature in features}\n",
        "\n",
        "# Create the Dataset object\n",
        "dataset = Dataset.from_dict(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4NQk4xXIJUIF"
      },
      "outputs": [],
      "source": [
        "# Extract the 'text' field\n",
        "text_data = data['text']\n",
        "\n",
        "# Specify the path and name of the output text file\n",
        "output_file_path = 'C:\\\\Users\\\\pranu\\\\Desktop\\\\Podcast_generation\\\\podcasts_text.txt'\n",
        "\n",
        "# Write the 'text' data to the text file\n",
        "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "    for item in text_data:\n",
        "        file.write(str(item) + '\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vCmpiKe4UX5h"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU \n",
        "\n",
        "\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, GitHub repository (https://github.com/minimaxir/gpt-2-simple). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkpRgBCBS2_",
        "outputId": "af4386d1-96b7-41b6-ce56-0ae432c43c60"
      },
      "outputs": [],
      "source": [
        "#pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "#from google.colab import files"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUmTooTW3osf",
        "outputId": "495b54f3-ae96-4e39-9f0f-f3be4c836729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun May 21 21:58:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wSlgXoDPCR",
        "outputId": "b66a1829-b6a4-4e56-a4cc-911047a0125d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 193Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 5.54Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 517Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:09, 53.6Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 474Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 5.66Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 6.56Mit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "outputs": [],
      "source": [
        "file_name = \"podcasts_text.txt\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "69cb03be-df3e-40e4-e6da-79a94517fea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:16<00:00, 16.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset has 3707192 tokens\n",
            "Training...\n",
            "[10 | 28.01] loss=3.25 avg=3.25\n",
            "[20 | 49.12] loss=3.29 avg=3.27\n",
            "[30 | 70.66] loss=3.22 avg=3.26\n",
            "[40 | 92.59] loss=3.15 avg=3.23\n",
            "[50 | 114.94] loss=3.23 avg=3.23\n",
            "[60 | 137.40] loss=3.23 avg=3.23\n",
            "[70 | 159.51] loss=3.17 avg=3.22\n",
            "[80 | 181.71] loss=3.11 avg=3.21\n",
            "[90 | 204.10] loss=3.16 avg=3.20\n",
            "[100 | 226.42] loss=3.12 avg=3.19\n",
            "[110 | 248.71] loss=3.20 avg=3.19\n",
            "[120 | 271.00] loss=3.23 avg=3.20\n",
            "[130 | 293.29] loss=3.20 avg=3.20\n",
            "[140 | 315.61] loss=3.21 avg=3.20\n",
            "[150 | 337.94] loss=3.12 avg=3.19\n",
            "[160 | 360.29] loss=3.13 avg=3.19\n",
            "[170 | 382.63] loss=3.00 avg=3.18\n",
            "[180 | 404.97] loss=3.22 avg=3.18\n",
            "[190 | 427.28] loss=3.28 avg=3.18\n",
            "[200 | 449.57] loss=3.17 avg=3.18\n",
            "======== SAMPLE 1 ========\n",
            ". You know, I'm not an optimist. I'm certainly not a pessimist. But I think that we're gonna see that happen because for a long-term perspective, the future of the Earth seems like to be the only thing we're gonna have. And you don't wanna see an early extinction because that's the idea and the reality is not there. We've got no hope for another planet, for some of our most significant social events going forward. And you're right in saying that there might not be life after we die. No. We haven't had many of our lives. You're right. And what's a life? Well, I think life is gonna be a very interesting thing in the near term if we don't live in the past and not the present. Yeah. So you're right, but we're gonna kind of go out onto the future. You're right. All right. So how do you think about what's gonna be like, like the future of life? What is life? What am I gonna live at all these years? What's gonna happen in the future? What is the future of consciousness? Do you think, you know how existentialists are gonna go after life for as long as there are? Yeah, we would have a really different world. So we're living in a world that's far away and far away. And it could very easily be a different world, you know. So we're literally living in a space called the past. So in the past time, we're gonna be alive. We're gonna be living out the history we're living from now on. And we're gonna have no memories of it anymore. And we're gonna be like on the planet. Yeah. Oh, okay. What do you think about the state of the universe? Do you think like it or not, if we were in a future, we would be living in or out of the past, you wouldn't be in it, and that is a really interesting philosophical question. And it's really hard to answer because we do it all in the past. And we're thinking about all the things that went before and the future, and the future seems like to be like that is a rather interesting question, right? And it is so fascinating. What do you think are our future predictions about what the universe is gonna look like? Are we gonna make an honest prediction and not make an exaggerated one? Are we gonna actually live on the planet and not the future? You know, it's gonna be interesting to kind of explore it. Yeah. I think it's gonna be interesting. It's gonna be interesting. And it's gonna be interesting to think about it and try to understand it. Well, in terms of the universe, what is it, what is it gonna do? There's gotta be a lot of stuff at play. I don't know what to hope for. I don't know. I don't know where we hope or I don't know. I'm just going to ask you for advice and advice. You know what? All right. Like how much is the universe gonna change and what is this. I, I'm gonna give you the advice of the following advice and I will not give you advice. I'm gonna give you advice because you will be one of the closest friends that the human race have ever had. You're the closest thing to a God. And I don't know the answer to it. That's just my intuition. Do you know what it is? What's it gonna do? All right. What I mean, we're gonna try to communicate about it like what's gonna happen. We want to communicate with each other and what's gonna happen. The universe will have a pretty simple version of us communicating in our collective consciousness, but we're gonna make a much more complex version of it, but I think that what we think about, that's gonna be very interesting to kind of build bridges and to try to understand all the bits and pieces of it and to think about it. Yeah. It will likely be the best and the most elegant bridge in the universe that we've ever built. And the only way or we can get to it is if we live in a future that's gonna feel better about itself. So I'm gonna, I guess, be the best bridge that we've ever thought the universe could have been. And I know, as a young scientist, I'm gonna hope that we're gonna make a bridge to get to a better kind of reality. I know that I don't want to live in a new universe until there's a better kind of reality. So to get there, I hope from this point forward, we're gonna do a lot of research and make a lot of sacrifices. Okay. I'm gonna be humble. I'm gonna look the other way. And that's gonna be an incredible experience. That's gonna be an amazing experience. That's gonna be an incredible experience. Yeah, so you think about when Elon\n",
            "\n",
            "[210 | 484.77] loss=3.20 avg=3.19\n",
            "[220 | 507.14] loss=3.09 avg=3.18\n",
            "[230 | 529.45] loss=3.09 avg=3.18\n",
            "[240 | 551.75] loss=2.95 avg=3.17\n",
            "[250 | 574.08] loss=3.02 avg=3.16\n",
            "[260 | 596.46] loss=2.97 avg=3.15\n",
            "[270 | 618.79] loss=3.24 avg=3.15\n",
            "[280 | 641.11] loss=3.08 avg=3.15\n",
            "[290 | 663.42] loss=3.12 avg=3.15\n",
            "[300 | 685.74] loss=3.05 avg=3.15\n",
            "[310 | 708.13] loss=3.06 avg=3.14\n",
            "[320 | 730.51] loss=3.11 avg=3.14\n",
            "[330 | 752.89] loss=3.14 avg=3.14\n",
            "[340 | 775.23] loss=3.03 avg=3.14\n",
            "[350 | 797.55] loss=2.97 avg=3.13\n",
            "[360 | 819.85] loss=3.04 avg=3.13\n",
            "[370 | 842.19] loss=3.07 avg=3.13\n",
            "[380 | 864.53] loss=3.06 avg=3.13\n",
            "[390 | 886.88] loss=3.01 avg=3.12\n",
            "[400 | 909.19] loss=2.98 avg=3.12\n",
            "======== SAMPLE 1 ========\n",
            " a good time for us to learn to use them? Not at all. So the whole approach is to get us from the beginning to the end of an evolution and have ourselves be good stewards of the universe. If you are doing that correctly, what is this universe? I'm using a lot of terms like a fractal and a random element. It's got random. It's got random. And what the fractal has is a random number generator that randomly picks up random numbers. In the simplest form, that random number is a randomly selected number. So a fractal with a randomly selected number that is randomly generated is a fractal with random number. That's what the random number is. So that fractally has a random number. So what it does is it randomly generates random numbers around that random number. Which means that it can't just random number. The randomness will never be random. It will be randomness. And so then the thing can be anything. What is this part? Is it random or is it random? It will probably come up randomly. So what is that part of the universe? The process that produces random numbers in this process that gives rise to fractals is called the Cambrian explosion. So at the start of the Cambrian explosion, it got so big that it was starting to look like there were galaxies that would have been created over 200,000 years ago. And that's what, I mean, it makes a great show because there's not a lot of time for that. It's just a, there's two seconds in a day when you get to go through that time window. So when you're done, you're right in the time window. You can't get off to any of that at that point in time, right? You get to this very early stage of the Cambrian explosion. It's a sort of the opposite of what we see with our normal evolutionary process at the beginning of the 20th century. Basically, I think, we had this early stage of the Cambrian explosion that was mostly a matter of just the initial conditions. And then those are the stages. And then then the next round of Cambrian explosion happens, which is how much of the galaxy gets to be that age, which is why this is so important early in the Cambrian explosion. So so we had to do this, but again, our normal evolutionary process. We can do that for any type of chemical reaction or even things like that. Now what's very frustrating about the Cambrian explosion is that it occurred in such a remote place. The Cambrian explosion is unique because it happened in such a place where we couldn't know anything. We couldn't go to any of these weird places. So what does this mean? It means that if you look at the history of chemistry, we know where the Cambrian explosion happened because it's just a matter of the chemistry, right? And these are two things that are really important. So we need to have them at the same time. And so there's two sides to that. We don't know where the Cambrian explosion happened. Well, let's say a few years from now. So the first thing is the Cambrian explosion happens at the origin of supernova or supernova. And that is the first explosion that comes when there's a supernova, right? If you had to choose between a supernova or not, that's probably the one that will give you the best results. So in fact, we use very precise calculations of how long it takes to destroy one supernova after another. It's called a perigee explosion. So perigee is very nice to know because you could actually be right in the middle of something coming and then it'll do very little harm to your life. In fact, if I remember, I'm not sure I remember. But if the thing explodes before that perigee explosion, then it could mean something that's not as important. Maybe it's an important thing you didn't tell me. So what do we mean by perigee explosion? We mean that this explosion is the worst thing that could happen to any civilization in the history of humanity. And so I mean, if you just start talking about all the history of humans, which is fascinating what they were like before and what they did in terms of the Cambrian explosion, it's very interesting to think about whether human civilization in time was like good enough to do what the humans did in order to make sure that this thing happened anyway. What do you make it? What does this say about the nature of the current state and how long have we been able to hold this conversation? How did this happen? What's your sense? Is it true that in the same time period, we have basically survived the Cambrian explosion? In other words, how do the people of the last couple of millennia cope with the Cambrian explosion? Do you think that it will happen in the very time that has been measured, the timeframe of the Cambrian explosion\n",
            "\n",
            "[410 | 942.76] loss=3.03 avg=3.11\n",
            "[420 | 965.13] loss=3.18 avg=3.12\n",
            "[430 | 987.48] loss=3.07 avg=3.12\n",
            "[440 | 1009.82] loss=3.07 avg=3.11\n",
            "[450 | 1032.11] loss=2.94 avg=3.11\n",
            "[460 | 1054.42] loss=2.92 avg=3.10\n",
            "[470 | 1076.75] loss=3.03 avg=3.10\n",
            "[480 | 1099.08] loss=3.05 avg=3.10\n",
            "[490 | 1121.43] loss=2.97 avg=3.10\n",
            "[500 | 1143.78] loss=3.02 avg=3.10\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 1173.97] loss=3.10 avg=3.10\n",
            "[520 | 1196.50] loss=3.12 avg=3.10\n",
            "[530 | 1218.81] loss=2.94 avg=3.09\n",
            "[540 | 1241.10] loss=3.02 avg=3.09\n",
            "[550 | 1263.49] loss=3.12 avg=3.09\n",
            "[560 | 1285.83] loss=3.06 avg=3.09\n",
            "[570 | 1308.11] loss=2.98 avg=3.09\n",
            "[580 | 1330.47] loss=3.06 avg=3.09\n",
            "[590 | 1352.82] loss=3.03 avg=3.09\n",
            "[600 | 1375.15] loss=3.08 avg=3.09\n",
            "======== SAMPLE 1 ========\n",
            " the sort of, you know, it was like a very, very smart team in all these different industries. It was, we were working for $2 a day and $3 a day. And I remember one of my friends I had working at the Department of Defense, the Defense Department Office. We were on call and we had a lot of conversations. And then I said to somebody sitting in the office, we work together. He said, come down. This is the first time since 1984 that we got together. We're on call. And so, you know, the guys that I worked in that, they were very smart. They were very, very intelligent. If you look at how many years before that I was working, how many years before that, were there conversations that we had that I found really interesting? And, you know, they were very intelligent, very hard working people. And one of them even brought me from MIT, where he was an intern, like for an internship, it was like, okay, come back. You know, if we're going to do this, you must go there. They were really intelligent and have a lot of heart, but I did not understand. And that was for a very long time, and if you look at the amount of money and all the time people have invested into this project. They're not that much investment, but they have a lot of heart and are a little bit of a competitor to what we're doing now. So I think, you know, at least we're now, look, we're not doing as much. We do a lot of work with all the big players of DOD, Lockheed Martin. So, you know, all this stuff happens, you know, with our military. We do a little bit with DOD, with Lockheed for many, many years. We have a few different companies. We had no contracts with those two major companies. I mean, they built this thing. They built the thing as a hobby. You know, it's a hobby. So I believe that the DOD, the Pentagon, the Defense Department, they're working together a lot. And they were really really smart. They were very smart, very hard working people. They'd come up with something in your life, something you really want to achieve, even if it's just for a decade. They were very smart. And I love them. I don't mean to call them that at this point, but they were very smart and really thought that their own, they thought of it as a hobby, and they had some good ideas and had done some good things there and they thought it was the right thing to do. So they created the world's first, you know, a basic airframe, with airframe sensors, without having to actually go to a big, complex test stand. I mean, it's that small number of things, the size of the base is not, and that does not, even though you're trying to do that today, is the smallest. It's very much like a human in an alien form. It's a big, complex system. And as an artist, it's always exciting to do something that is more human. You've seen, I think the most of the people that have worked with us to do the work they've done on the Defense Force has actually, I think, maybe the biggest influence by far has been on the Navy and Marines. How many years ago were they using a fighter that had no radar to make the signal of the world? How many years ago were they using a radar for air traffic control, and how many? How about a radar? The Navy used one. We've seen a fighter with no radar in operations for many years, and it's still the biggest, if not strongest, of the four most powerful air force systems in the world. How many? How many? How many? How many? How many? How many? How many? How many? How many years ago? I think it's more of a very specific problem, but I guess that's the way the problem is played out in the Navy today. So, we think of things as really complex systems that have really low radar accuracy. So, there's no radar. So our radar was very high. So, there's no radar. It's very good. It's good. And so, you use one radar and you do three radar, and it's very, very, and it uses those three radar as a sensor for all the other system systems. It uses that two radar just as a sensor as a sensor for the other system. You can do it any number of different ways. So what are the two biggest problems we've talked about now? We have no radar. So, there's very high radar accuracy. We don't have radar in the Navy to know the difference. So, so, that's like, we are using technology that's like, what, oh, they've never used radar. They've never\n",
            "\n",
            "[610 | 1409.11] loss=3.08 avg=3.09\n",
            "[620 | 1431.46] loss=2.91 avg=3.08\n",
            "[630 | 1453.83] loss=2.86 avg=3.08\n",
            "[640 | 1476.19] loss=3.25 avg=3.08\n",
            "[650 | 1498.55] loss=3.00 avg=3.08\n",
            "[660 | 1520.89] loss=3.07 avg=3.08\n",
            "[670 | 1543.17] loss=3.14 avg=3.08\n",
            "[680 | 1565.50] loss=3.04 avg=3.08\n",
            "[690 | 1587.84] loss=2.97 avg=3.08\n",
            "[700 | 1610.15] loss=3.02 avg=3.08\n",
            "[710 | 1632.51] loss=2.98 avg=3.07\n",
            "[720 | 1654.86] loss=2.95 avg=3.07\n",
            "[730 | 1677.21] loss=3.01 avg=3.07\n",
            "[740 | 1699.57] loss=3.01 avg=3.07\n",
            "[750 | 1721.88] loss=3.01 avg=3.07\n",
            "[760 | 1744.22] loss=2.98 avg=3.07\n",
            "[770 | 1766.52] loss=3.09 avg=3.07\n",
            "[780 | 1788.83] loss=2.92 avg=3.06\n",
            "[790 | 1811.16] loss=3.03 avg=3.06\n",
            "[800 | 1833.46] loss=3.01 avg=3.06\n",
            "======== SAMPLE 1 ========\n",
            " sleep, all those kinds of things can be bad on their human and artificial intelligence. And so the question there, is that, and perhaps, or is there more philosophical or social challenges from, or from the different perspectives, is there that we don't know that the answer? Yeah. So is there the sense that the human consciousness is in some sense more complex in some places? If so, can we talk about what's in, in what parts of the human brain, how difficult are these challenges? And do we think that's the answer to both the existential and artificial intelligence, or do we just think it's a bit of both? Yeah. I mean, one of the big problems of artificial intelligence is we know very little about it. There's no reason to think we shouldn't come up with a very different level of complexity on the human side. You say a more advanced AI system would have a better level of intelligence. In some ways, do you think there's more to it than that? Do you agree with the big picture view? Right now, most of the progress we've seen is the technological progress of humans, which means we're still kind of in the long past. The machine learning we're doing now, and the learning on AI, is a sort of long time coming. AI is probably about 10 years away, and it might just go all the way in 10 years or something, but now it's been a decade to a decade since there was any kind of breakthrough, and we're just kind of on the road of how to make progress for human beings. So in terms of AI, there is, again, this idea of artificial intelligence, is it a deep level of understanding that, that we're, as human beings, as complex beings, that the human consciousness? And it's just, again, not a one size fits all view, because I think the AI world is a multi-computation world as we kind of are starting to get to understand this whole thing that happens all the time with human beings. But in the long arc of history, we've actually got a lot of progress in the human brain is, and artificial intelligence is very much part of that. So the whole thing, if you take a lot of effort, you're really making progress. But how do we make progress even into humanhood? We have the intelligence and the empathy. How do we make progress in the human level? The human level, the empathy, the human level is really important because we have so much progress at the level of the human. Okay. Yeah. So what will be the future? Okay. And the kind of progress we're making now really, in the short-term, I'll go with human level progress, but the short-term progress, the progress I've got now is very, very minimal. But let's make it work. Yeah, I mean, for instance, the first step is to have a computer, right? Do you understand the world? So there will be that question and so on. I would say that there are no limits to the human level. But that, if we make it work as well as human level, then the human level is really close. And I would say that in principle, the current AI system is not even close. But, to make it work as well as human level, there's also the fact that it's a high percentage of humans have no idea where they're actually going with it. And sometimes a computer might not do anything. I don't know, maybe some of the first AI systems that the people that invented it, if they made it or if they knew where they were, would have no idea. It's just, it's kind of, I guess the biggest thing you really would say is we will eventually come to an AI system where it's not possible. At the very least, and maybe it doesn't have as far as I want of the distance, but the world is a big place. Is there an AI system that is capable of doing something? So you mentioned, you mentioned in AI, the human level systems. Yeah. So what we would do is we would have an early version of an AI machine that, you know, we've been developing all the time, which is actually, you know, we are in the last year or two of this, two of these very interesting artificial general intelligence projects, some of which are called neural networks, right? Neural networks work similarly to natural language, or it works the same way to solve spatial, right? Can you do the same level of spatial resolution of an object in this world as someone might be able to do in the real world? Okay. And then what people call this kind of a neural network system, which is basically like a neuron, a thing. A neuron is an example of an artificial general intelligence, and it's just like a little piece of software that you kind of, but in theory actually has no information. It's not telling anything. It's\n",
            "\n",
            "[810 | 1867.32] loss=3.18 avg=3.06\n",
            "[820 | 1889.66] loss=2.85 avg=3.06\n",
            "[830 | 1912.01] loss=2.89 avg=3.06\n",
            "[840 | 1934.38] loss=2.80 avg=3.05\n",
            "[850 | 1956.73] loss=2.98 avg=3.05\n",
            "[860 | 1979.07] loss=2.69 avg=3.05\n",
            "[870 | 2001.41] loss=2.82 avg=3.04\n",
            "[880 | 2023.76] loss=3.07 avg=3.04\n",
            "[890 | 2046.10] loss=3.04 avg=3.04\n",
            "[900 | 2068.41] loss=2.97 avg=3.04\n",
            "[910 | 2090.72] loss=2.77 avg=3.04\n",
            "[920 | 2113.04] loss=2.99 avg=3.04\n",
            "[930 | 2135.35] loss=2.92 avg=3.03\n",
            "[940 | 2157.68] loss=2.94 avg=3.03\n",
            "[950 | 2179.98] loss=3.00 avg=3.03\n",
            "[960 | 2202.30] loss=2.86 avg=3.03\n",
            "[970 | 2224.68] loss=2.74 avg=3.02\n",
            "[980 | 2247.04] loss=2.99 avg=3.02\n",
            "[990 | 2269.43] loss=2.96 avg=3.02\n",
            "[1000 | 2291.78] loss=3.14 avg=3.02\n",
            "Saving checkpoint/run1/model-1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxL77nvAMAX",
        "outputId": "8ce72b5a-4312-40ce-d5bb-5a17656bdc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint\\run1\\model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint\\run1\\model-1000\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "37dac762-7716-412c-d5c9-944d07541aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"There is no doubt,\" said Mr. Obama, \"that I am not going to be able to win on the campaign trail.\"\n",
            "\n",
            "But for the first time in his presidency, Mr. Obama has been able to keep his word. The New York Times reported that while campaigning for the Democratic nomination, he has been able to earn only $823,000 on the ground in his bid for the White House, compared with $3,600 on the national stage.\n",
            "\n",
            "The most recent election, in which Mr. Obama won the popular vote by a narrow margin, was in 1992, when George W. Bush won the popular vote by a narrower margin.\n",
            "\n",
            "\"I can tell you from experience that it is difficult to push through big gerrymandering when you are running against so many people on the ground,\" Mr. Gore said earlier this month. \"And I think that's why we have a real challenge, one that is going to come from the people of New York City.\"\n",
            "\n",
            "Mr. Obama's historic victory in 2012 was a testament to his campaign's ability to protect the American people from \"unfair and deceptive\" political campaigns, said Mr. Shulman, who works for the Campaign for America's Future.\n",
            "\n",
            "Mr. Obama's victory, he said, was \"a big step forward for New Yorkers and a big step back for the nation.\"<|endoftext|>Losing a child's virginity is not an easy thing to do, especially to a young girl.\n",
            "\n",
            "But what if you did something that is even harder to bear? You could never turn your back on your sexual desire without risking the loss of your virginity.\n",
            "\n",
            "The sexual situation in Britain is much more complicated than the burden of having a child.\n",
            "\n",
            "It's not uncommon for young girls to have several different sexual partners, and many don't even know they can have a child.\n",
            "\n",
            "This is because in many countries, the third or fourth person to have a child is considered the most common sex act.\n",
            "\n",
            "For example, in the UK, no more than 18 per cent of women have a partner.\n",
            "\n",
            "And in the United States, 23 per cent of women have two or fewer partners.\n",
            "\n",
            "In other words, if you are a virgin and want your child to be happy and healthy, you need to have a partner who will act as a surrogate for you and your child.\n",
            "\n",
            "So if you have a child, you should never do this.\n",
            "\n",
            "Fortunately, there are many ways to have a child.\n",
            "\n",
            "In some countries, you can legally have your child through a third party.\n",
            "\n",
            "But in others, you have to make a choice.\n",
            "\n",
            "If you have a partner who has a sexual interest in you, you have to decide between a partner who should be your partner and a partner who should not be.\n",
            "\n",
            "If both partners have sexual interests, the best option is to have a third party.\n",
            "\n",
            "If both partners are legally married, the best option is to have a third party.\n",
            "\n",
            "If both partners have children, there's no question that they should get married if they want their child to be happy and healthy.\n",
            "\n",
            "Or if both partners have sex, you can have a third party.\n",
            "\n",
            "The best option is to have a third party.\n",
            "\n",
            "If you're thinking of becoming a partner, you should check with your local authority or other partners.\n",
            "\n",
            "If you're thinking of having a child, you should talk to your local health authority.\n",
            "\n",
            "If you're thinking of having a child, you should talk with your local health authority.\n",
            "\n",
            "If your partner is more than 6, you should have a third party.\n",
            "\n",
            "If your partner is between 8 and 12, you should have a third party.\n",
            "\n",
            "If your partner is 12 years or older, you should have a third party.\n",
            "\n",
            "If you're thinking about having a child, you should talk to your local health authority.\n",
            "\n",
            "A third party is just a way to have sex without being accompanied by a partner.\n",
            "\n",
            "It's not a means to an end, it's just a means to an end.\n",
            "\n",
            "You can have your child if you have a partner who has a sexual interest in you so you're happy and healthy.\n",
            "\n",
            "If you're thinking about having a child, you should talk to your local health authority.\n",
            "\n",
            "If you're thinking of having a child, you should talk to your local health authority.\n",
            "\n",
            "If you're thinking of having a child, you should talk to your local health authority.\n",
            "\n",
            "If you're thinking of having a child, you should talk to your local health authority.\n",
            "\n",
            "If you're thinking about having a child, you should talk to your local health authority.\n",
            "\n",
            "If your partner is younger than 6, you should have a third party.\n",
            "\n",
            "If your partner is 12 years or older, you should have a third party.\n",
            "\n",
            "If your partner is between 8 and 12 years, you\n"
          ]
        }
      ],
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DKMc0fiej4N",
        "outputId": "86dcfa45-31f3-49bb-d443-1033ad3c5e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't think you're giving me a choice when you say that. But I think you're giving me a choice in the sense that you're an interesting person. I'm probably a very interesting person, but I think you'd give me a choice. Yeah. That's a really interesting choice to take. I have a pretty good sense. I think you want to take an interesting person, but you can have a very important choice. And I don't think I can do that, but yeah. I think you want an interesting person. I think you want to take an interesting person, but you can have a very difficult choice. You're either going to win or you're going to lose. And so that's the interesting choice. And I just think that's a really interesting choice. You can have a very good choice. You can have a very difficult choice. You can have a very difficult choice. I think it's a really good way to take an interesting person. I think it's a really good choice. If you're going to do an interesting person, you need a very important choice. And if you're going to do an interesting person, you need a very interesting person. And so I think that's a really interesting choice. And I think you can have a very important choice. That's a really interesting choice. I think you can have a very interesting person. I think you can have a very interesting, I think you can have an interesting person. I think you can have a very interesting person. And I think in terms of the podcast, I think I have a very good sense of what it is that you want to do and I can have a very good sense of what it is that the people that I love are, I think, and that I can have a very good idea of what their goals are. And I think you have a very good idea of what your goals are. And I think that you have a very good idea of what it is that you want to do. And I think that you have a very good idea of what it is that you want to do. And I think you have a very good idea of what your goals are. If you're doing the podcast, you're doing the podcast. But I think that everything that's been said is true. I think that everything that's been said is true. And I think that the people that I don't know are the people that I love, the people that I love are the people that I love the more. And that's what I think it is. And it's what I think it is. I think you can have a very interesting choice. You can have a very interesting choice. But if you're going to do an interesting person, you need a very interesting. And if you're going to do an interesting person, you need a very interesting. And you have to have a good idea of what you want to do. And I think that's what the people that I love in general, and I think you can have a very interesting. And I think you can have a very interesting. And I think you can have a very interesting. And I think it's a very good. I think it's a very good. I think it's a very good. I think it's a very good. And I think it's a very good. I think it's a very good. I think it's a very good. And I think it's a very good. And I think it's a very good. I think it's a very good. And I think it's a very good. So that's what I think. So that's what I think. But I think you can have a very interesting. I think that you can have that. Like you think, okay, what's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What are your goals? What are your goals? What are your goals? What are your goals? What are your goals? What are your goals? What are your goals? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? What's your goal? That's my\n"
          ]
        }
      ],
      "source": [
        "gpt2.generate(sess,\n",
        "              length=1000,\n",
        "              temperature=0.7,\n",
        "              prefix=\"\",\n",
        "              # nsamples=1,\n",
        "              # batch_size=5\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_data = \"C:\\\\Users\\\\pranu\\\\Desktop\\\\Podcast_generation\\\\prompt_text.txt\" # Replace with the actual filename of your podcast text data\n",
        "with open(prompt_data, 'r') as file:\n",
        "    prompt_text = file.read().splitlines()\n",
        "\n",
        "prompt = str(prompt_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "g6dtTvSFymtl",
        "outputId": "217e79f4-6e06-47ec-cf4f-7de091997e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine Learning, my favorite kind of thing. Yeah, fully scalable neural networks. I've always just wanted to run what now I'd call natural language engagement and correlated learning models, that kind of stuff. I think the thing that I'm most excited about is that it gives us an additional layer on top of it to run more models. So it's not just, it's like a really large part of what's happened in this episode. Of the three episodes that I realized that next to this actual show\n"
          ]
        }
      ],
      "source": [
        "# Define the podcast script prompt\n",
        "#prompt = \"Machine Learning\" \n",
        "\n",
        "# Generate the podcast script\n",
        "script = gpt2.generate(sess,\n",
        "                       length=100,  # Adjust the desired length of the script\n",
        "                       temperature=0.9,\n",
        "                       prefix=prompt,\n",
        "                       nsamples=1,\n",
        "                       batch_size=1,\n",
        "                       include_prefix=False,\n",
        "                       return_as_list=True\n",
        "                       )\n",
        "\n",
        "# Print the generated script\n",
        "print(script[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_file = \"C:\\\\Users\\\\pranu\\\\Desktop\\\\Podcast_generation\\\\input.txt\"  # Replace with the desired output file name and path\n",
        "\n",
        "with open(output_file, 'w') as file:\n",
        "    for line in script:\n",
        "        file.write(line + '\\n')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsUd_jHgUZnD"
      },
      "outputs": [],
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAe4NpKNUj2C"
      },
      "outputs": [],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xInIZKaU104"
      },
      "outputs": [],
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "outputs": [],
      "source": [
        "!kill -9 -1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SvZ2zvPYmkrq"
      },
      "source": [
        "Voice Conversion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh5p3tDYmYc4",
        "outputId": "a60ce681-d554-4091-e87b-2b52cabfe4ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.3.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.27.1)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting playsound\n",
            "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: playsound\n",
            "  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7019 sha256=120813a76e05b4fa1e8a886df33acc5042029a7c677814ab3adc6e26792dd8be\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n",
            "Successfully built playsound\n",
            "Installing collected packages: playsound\n",
            "Successfully installed playsound-1.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install gTTS\n",
        "pip install playsound\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOSYfckKmnmE",
        "outputId": "01b2ce5c-bfcc-4a82-fa2d-e4849e1b222c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:playsound:playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n"
          ]
        }
      ],
      "source": [
        "from gtts import gTTS\n",
        "from playsound import playsound\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "flmLHBKZmrt-"
      },
      "outputs": [],
      "source": [
        "tts = gTTS(script[0])\n",
        "tts.save('output.mp3')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ph28v00pso9"
      },
      "outputs": [],
      "source": [
        "from playsound import playsound\n",
        "\n",
        "audio_file = '/content/output.mp3'  # Replace with the actual path to your audio file\n",
        "playsound(audio_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "5C0800y_muIQ",
        "outputId": "759a4db3-7e6e-4f2e-eb8f-8d7ad7b2ab70"
      },
      "outputs": [],
      "source": [
        "playsound('output.mp3')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WE1qsD2HrmTh"
      },
      "source": [
        "Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_eE0Q5Wjm2QQ"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "from nltk.translate.bleu_score import corpus_bleu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uqQXCOuQnKGx"
      },
      "outputs": [],
      "source": [
        "podcast_data = \"C:\\\\Users\\\\pranu\\\\Desktop\\\\Podcast_generation\\\\podcasts_text.txt\" # Replace with the actual filename of your podcast text data\n",
        "with open(podcast_data, 'r') as file:\n",
        "    podcast_text = file.read().splitlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU score: 0.003140936345886799\n"
          ]
        }
      ],
      "source": [
        "bleu_score = corpus_bleu([podcast_text], script)\n",
        "print(\"BLEU score:\", bleu_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "iCNAkhHfnSte",
        "outputId": "8f1cbc62-9104-45b8-bde9-48ada92166ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU score: 0.003140936345886799\n"
          ]
        }
      ],
      "source": [
        "# Prepare reference text and generated text for BLEU score calculation\n",
        "# reference_text = [[text.split()] for text in podcast_text]\n",
        "# generate_text = [[text.split()] for text in script]\n",
        "import gpt_2_simple as gpt2\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = corpus_bleu([podcast_text], script)\n",
        "print(\"BLEU score:\", bleu_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_response(input_text):\n",
        "  #input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "  #outputs = model.generate(input_ids)\n",
        "  response_text = gpt2.generate(sess, length=10, prefix = input_text, temperature=0.9, return_as_list=True)[0]\n",
        "  return response_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_response(prompt):\n",
        "    generated_text = gpt2.generate(sess, length=10, temperature=0.9, return_as_list=True)[0]\n",
        "    print(generated_text)\n",
        "    return generated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "interface = gr.Interface(\n",
        "  fn=generate_response, \n",
        "  inputs=gr.inputs.Textbox(label=\"Input\"), \n",
        "  outputs=gr.outputs.Textbox(label=\"Response\")\n",
        ")\n",
        "\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_textbox = gpt2.generate(sess, length=10, prefix = \"Machine Learning\", temperature=0.9, return_as_list=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine Learning Deep Learning\n",
            "\n",
            "Donations, Whenever Possible\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(output_textbox[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "moHatEfXk5Oq",
        "outputId": "ddecce44-951c-445a-9b41-7e62a05b9d5c"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def generate_text(input_text):\n",
        "    # Process the input text and generate the desired output\n",
        "    output_textbox = gpt2.generate(sess, length=10, prefix = input_text, temperature=0.9, return_as_list=True)\n",
        "    output_textbox = str(output_textbox[0])\n",
        "    return output_textbox\n",
        "\n",
        "# Create a text input interface using Gradio\n",
        "input_textbox = gr.inputs.Textbox(lines=1, label=\"Enter Text\")\n",
        "\n",
        "# Create an output interface to display the generated text\n",
        "output_textbox = gr.outputs.Textbox(label=\"Generated Text\")\n",
        "\n",
        "\n",
        "# Create the Gradio app\n",
        "grapp = gr.Interface(fn=generate_text, inputs=input_textbox, outputs=output_textbox)\n",
        "\n",
        "# Run the Gradio app\n",
        "grapp.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV0MY6HoqmnQ"
      },
      "outputs": [],
      "source": [
        "input_textbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3TQd9GOrrp9k"
      },
      "outputs": [],
      "source": [
        "def generate_text(prompt):\n",
        "    generated_text = gpt2.generate(sess, length=100, temperature=0.9, return_as_list=True)[0]\n",
        "    return generated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "U5q8WqlNrqq0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\", line 304, in __init__\n",
            "    self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3996, in as_graph_element\n",
            "    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 4075, in _as_graph_element_locked\n",
            "    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\n",
            "ValueError: Tensor Tensor(\"strided_slice:0\", shape=(1, None), dtype=int32) is not an element of this graph.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\routes.py\", line 422, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\blocks.py\", line 1323, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\blocks.py\", line 1051, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
            "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"C:\\Users\\pranu\\AppData\\Local\\Temp\\ipykernel_11480\\2737644470.py\", line 2, in generate_text\n",
            "    generated_text = gpt2.generate(sess, length=100, temperature=0.9, return_as_list=True)[0]\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\gpt_2_simple\\gpt_2.py\", line 477, in generate\n",
            "    out = sess.run(output)\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\", line 968, in run\n",
            "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\", line 1176, in _run\n",
            "    fetch_handler = _FetchHandler(\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\", line 485, in __init__\n",
            "    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\", line 276, in for_fetch\n",
            "    return _ElementFetchMapper(fetches, contraction_fn)\n",
            "  File \"C:\\Users\\pranu\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\", line 311, in __init__\n",
            "    raise ValueError(f'Argument `fetch` = {fetch} cannot be interpreted as '\n",
            "ValueError: Argument `fetch` = Tensor(\"strided_slice:0\", shape=(1, None), dtype=int32) cannot be interpreted as a Tensor. (Tensor Tensor(\"strided_slice:0\", shape=(1, None), dtype=int32) is not an element of this graph.)\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "input_textbox = gr.inputs.Textbox(label=\"Enter Prompt\")\n",
        "output_textbox = gr.outputs.Textbox(label=\"Generated Text\")\n",
        "\n",
        "grapp = gr.Interface(fn=generate_text, inputs=input_textbox, outputs=output_textbox)\n",
        "\n",
        "grapp.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 316Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 1.78Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 261Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:01, 8.09Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 347Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.72Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 4.06Mit/s]                                                      \n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained model models\\124M\\model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models\\124M\\model.ckpt\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"C:\\\\Users\\\\pranu\\\\Desktop\\\\Podcast_generation\\\\checkpoint_run1.tar\"   # Replace with the actual path to your checkpoint file\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=\"124M\", checkpoint_dir=checkpoint_path, run_name = 'run1', reuse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine Learning Toolkit (Andy Pratt). Last updated: April 2017\n",
            "\n",
            "Learn how to read data in Perl and in a Ruby program.\n",
            "\n",
            "Searchable databases.\n",
            "\n",
            "Develop a query or extract a data from a given table using embedding tags.\n",
            "\n",
            "Efficient and small social interaction.\n",
            "\n",
            "Stable code.\n",
            "\n",
            "Database based on rules as a way to establish a bottom-up model (e.g. each user tries their best to make a transaction, but there are no\n"
          ]
        }
      ],
      "source": [
        "text = gpt2.generate(sess, prefix=\"Machine Learning\", length=100, temperature=0.9, return_as_list=True)[0]\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012ed9b648c842c8aea0250c8af53e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114eb5be989447b3a0c8409c17f6a469",
            "max": 57264732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f222d8e940a64cb6b376db42272bc268",
            "value": 57264732
          }
        },
        "01d5c74954fb46ca93ef5c42ce023913": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02589d0ab582488ba3d0f5475737850f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a847efc99a4f1fbb48dbd3172ccc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad4f8f294d3b407e9b3feca7bac94d43",
              "IPY_MODEL_a5b8be414dfc4fb488c716f4e46f727b",
              "IPY_MODEL_0792ad27b703412eb9cb2654e530f206"
            ],
            "layout": "IPY_MODEL_5d7f2327ff7e48d08004afcbae096ed3"
          }
        },
        "0792ad27b703412eb9cb2654e530f206": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea23059a1732430db64d660ab52ed138",
            "placeholder": "​",
            "style": "IPY_MODEL_13d594f7ea9b43d7a017d0d1e3fd14a6",
            "value": " 1/1 [00:01&lt;00:00,  1.34s/it]"
          }
        },
        "079ebbc5439e4a01be35c19f83c0323a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1df9667673a94b38bb1b3d7378eae1c8",
              "IPY_MODEL_39c5a35c1973429180133ad23e8a5cde",
              "IPY_MODEL_be54948112194cc09efefbbe2abdd6f5"
            ],
            "layout": "IPY_MODEL_ff2a2d04d1ff4d308bd9d8f01fe7e279"
          }
        },
        "085d5940dc12453f84bace41bb4aa158": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fe740553f249b698b2eacd3eac1245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb8d0bec0d046a382ee67ee20daaf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "114eb5be989447b3a0c8409c17f6a469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d594f7ea9b43d7a017d0d1e3fd14a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df9667673a94b38bb1b3d7378eae1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af3a1d702f54e0a9832e7ca816eebaa",
            "placeholder": "​",
            "style": "IPY_MODEL_02589d0ab582488ba3d0f5475737850f",
            "value": "Downloading readme: 100%"
          }
        },
        "2af3a1d702f54e0a9832e7ca816eebaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f99a6a23644458bf13189cf39ea8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39c5a35c1973429180133ad23e8a5cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d5c74954fb46ca93ef5c42ce023913",
            "max": 3461,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bb8d0bec0d046a382ee67ee20daaf0c",
            "value": 3461
          }
        },
        "3d68dbef5c464acea2fcac250fc37a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c78fd8973b4bbc9c79d6e135f38f26",
            "placeholder": "​",
            "style": "IPY_MODEL_634965bb3d074aa3a54a8920238be256",
            "value": "Downloading data: 100%"
          }
        },
        "41c78fd8973b4bbc9c79d6e135f38f26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8079d080f8435bacf10960886bce47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1d58f83ac884c368b7387c594b1aed9",
              "IPY_MODEL_50f17a9741df42cc89466b6d187c7463",
              "IPY_MODEL_ae019d943fdf4b468409d3806a276117"
            ],
            "layout": "IPY_MODEL_85365a90daaf4a068a780ee327071586"
          }
        },
        "4c52bf9970514d35b25790ea41294c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4edf1d12ece04b33b08f7d443aede5c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb5f9e344914bfcb97565288e3b8aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f17a9741df42cc89466b6d187c7463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d758df3421364210b59ba9f9c543c3c0",
            "max": 346,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38f99a6a23644458bf13189cf39ea8f9",
            "value": 346
          }
        },
        "52f01f5517874774be05bc06515f2ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb5f9e344914bfcb97565288e3b8aa5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf33f5aa65014c6c98a2710b82d7d181",
            "value": 1
          }
        },
        "5832d418ac50402a911abd9efe7b41ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d7f2327ff7e48d08004afcbae096ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634965bb3d074aa3a54a8920238be256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "687d3c1fb2af40bdbf452f5c18d5f4cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be3bdbcc1cd4245938a4e11a0b313b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "721d993785684198a34dd91d64764c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726ec8485e2041bbb62f106010baa39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "780462fb987e4cafab7b113f5ede7879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "783c071afd6c43339a625317a74e278c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d68dbef5c464acea2fcac250fc37a9d",
              "IPY_MODEL_012ed9b648c842c8aea0250c8af53e3b",
              "IPY_MODEL_bec8e1c5b1484cfe9b42ebc64ea24b98"
            ],
            "layout": "IPY_MODEL_085d5940dc12453f84bace41bb4aa158"
          }
        },
        "7b23f26733dc4de8986b4d64a2c77d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d32d3a63c0e4215aa8e7b8c181c029b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0bbd06fed949fa854b4785eee98a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8421331470284617859128639ce92a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_687d3c1fb2af40bdbf452f5c18d5f4cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4c52bf9970514d35b25790ea41294c36",
            "value": "Extracting data files: 100%"
          }
        },
        "85365a90daaf4a068a780ee327071586": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8d2df08448294a609b69c9174e4bc532": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac4effbf76245278743b1163a1319ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b8be414dfc4fb488c716f4e46f727b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e0bbd06fed949fa854b4785eee98a6d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_726ec8485e2041bbb62f106010baa39a",
            "value": 1
          }
        },
        "aaf423b5d9fa48e59bac72ae3b1d2053": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4f8f294d3b407e9b3feca7bac94d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d32d3a63c0e4215aa8e7b8c181c029b",
            "placeholder": "​",
            "style": "IPY_MODEL_721d993785684198a34dd91d64764c4d",
            "value": "Downloading data files: 100%"
          }
        },
        "ae019d943fdf4b468409d3806a276117": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edf1d12ece04b33b08f7d443aede5c2",
            "placeholder": "​",
            "style": "IPY_MODEL_c0eb591f9e1742299b99fdf90c9dc634",
            "value": " 346/346 [00:00&lt;00:00, 687.35 examples/s]"
          }
        },
        "be54948112194cc09efefbbe2abdd6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac4effbf76245278743b1163a1319ff",
            "placeholder": "​",
            "style": "IPY_MODEL_5832d418ac50402a911abd9efe7b41ac",
            "value": " 3.46k/3.46k [00:00&lt;00:00, 183kB/s]"
          }
        },
        "bec8e1c5b1484cfe9b42ebc64ea24b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d2df08448294a609b69c9174e4bc532",
            "placeholder": "​",
            "style": "IPY_MODEL_6be3bdbcc1cd4245938a4e11a0b313b7",
            "value": " 57.3M/57.3M [00:00&lt;00:00, 92.9MB/s]"
          }
        },
        "bf33f5aa65014c6c98a2710b82d7d181": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0eb591f9e1742299b99fdf90c9dc634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d58f83ac884c368b7387c594b1aed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf423b5d9fa48e59bac72ae3b1d2053",
            "placeholder": "​",
            "style": "IPY_MODEL_08fe740553f249b698b2eacd3eac1245",
            "value": "Generating train split: 100%"
          }
        },
        "d758df3421364210b59ba9f9c543c3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba61360ebdb4177be59627fe6e330f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8421331470284617859128639ce92a25",
              "IPY_MODEL_52f01f5517874774be05bc06515f2ca8",
              "IPY_MODEL_e481859cedc846529a81ba413912155a"
            ],
            "layout": "IPY_MODEL_f2fd638e2b654a32bdb0754670ab739a"
          }
        },
        "e481859cedc846529a81ba413912155a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b23f26733dc4de8986b4d64a2c77d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_780462fb987e4cafab7b113f5ede7879",
            "value": " 1/1 [00:00&lt;00:00, 55.02it/s]"
          }
        },
        "ea23059a1732430db64d660ab52ed138": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f222d8e940a64cb6b376db42272bc268": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2fd638e2b654a32bdb0754670ab739a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2a2d04d1ff4d308bd9d8f01fe7e279": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
